{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Label 수정 및 EDA 용 200 data random sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../dataset\n"
     ]
    }
   ],
   "source": [
    "## 1. 기존 json 파일 수정\n",
    "\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "# json 파일 경로 설정\n",
    "json_file_path = '../../dataset/train.json'\n",
    "dataset_path = os.path.dirname(json_file_path)\n",
    "print(dataset_path)\n",
    "\n",
    "with open(json_file_path, 'r') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# 모든 'annotations'에 \"segmentation\": [] 추가\n",
    "for annotation in json_data['annotations']:\n",
    "    annotation['segmentation'] = []\n",
    "\n",
    "# 모든 이미지 파일 이름에서 'train/' 제거\n",
    "for image in json_data['images']:\n",
    "    image['file_name'] = image['file_name'].replace('train/', '')\n",
    "\n",
    "# 새 파일 이름 설정\n",
    "new_json_file_name = 'train_for_label.json'\n",
    "new_json_file_path = os.path.join(dataset_path, new_json_file_name)\n",
    "\n",
    "with open(new_json_file_path, 'w') as file:\n",
    "    json.dump(json_data, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|██████████| 4884/4884 [01:03<00:00, 77.42it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../../dataset\\\\train_for_label\\\\annotations\\\\instances.json'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. 파일 및 폴더 정리\n",
    "\n",
    "train_folder_path = os.path.join(dataset_path, 'train')\n",
    "\n",
    "new_file_name = \"instances.json\"\n",
    "new_folder_name = \"train_for_label\"\n",
    "new_folder_path_images = os.path.join(dataset_path, new_folder_name,'images')\n",
    "new_folder_path_annotations = os.path.join(dataset_path, new_folder_name,'annotations')\n",
    "\n",
    "if not os.path.exists(new_folder_path_images):\n",
    "    os.makedirs(new_folder_path_images)\n",
    "\n",
    "if not os.path.exists(new_folder_path_annotations):\n",
    "    os.makedirs(new_folder_path_annotations)\n",
    "\n",
    "# for file_name in os.listdir(folder_path):\n",
    "for file_name in tqdm(os.listdir(train_folder_path), desc=\"Copying images\"):\n",
    "\n",
    "    if file_name.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "        shutil.copy(os.path.join(train_folder_path, file_name), new_folder_path_images)\n",
    "        \n",
    "new_file_path_for_json = os.path.join(new_folder_path_annotations, new_file_name)\n",
    "shutil.copy(new_json_file_path, new_file_path_for_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Random sampling for EDA\n",
    "\n",
    "with open(new_file_path_for_json, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "total_images = 4883\n",
    "sample_size = 200\n",
    "\n",
    "# 200개의 무작위 이미지 ID 생성\n",
    "selected_image_ids = random.sample(range(total_images), sample_size)\n",
    "\n",
    "selected_filenames = [f\"{str(id).zfill(4)}.jpg\" for id in selected_image_ids]\n",
    "\n",
    "# JSON 파일 불러오기\n",
    "with open(new_file_path_for_json, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "filtered_images = [image for image in data['images'] if image['file_name'] in selected_filenames]\n",
    "filtered_annotations = [annotation for annotation in data['annotations'] if annotation['image_id'] in selected_image_ids]\n",
    "\n",
    "data['images'] = filtered_images\n",
    "data['annotations'] = filtered_annotations\n",
    "\n",
    "\n",
    "# 파일 복사\n",
    "destination_folder_for_images = os.path.join(dataset_path, 'train_random_filtered_200/images')\n",
    "if not os.path.exists(destination_folder_for_images):\n",
    "    os.makedirs(destination_folder_for_images)\n",
    "\n",
    "destination_folder_for_annotations = os.path.join(dataset_path, 'train_random_filtered_200/annotations')\n",
    "if not os.path.exists(destination_folder_for_annotations):\n",
    "    os.makedirs(destination_folder_for_annotations)\n",
    "\n",
    "for filename in selected_filenames:\n",
    "    source_file = os.path.join(new_folder_path_images, filename)\n",
    "    destination_file = os.path.join(destination_folder_for_images, filename)\n",
    "    \n",
    "    # 파일이 존재하는 경우에만 복사\n",
    "    if os.path.exists(source_file):\n",
    "        shutil.copy(source_file, destination_file)\n",
    "\n",
    "filtered_json_file_name = 'instances.json'\n",
    "filtered_json_file_path = os.path.join(destination_folder_for_annotations, filtered_json_file_name)\n",
    "\n",
    "# 수정된 JSON 파일 저장\n",
    "with open(filtered_json_file_path, 'w') as file:\n",
    "    json.dump(data, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Labeling 용 데이터 분할 n/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "레이블러: 종욱 / Label range: (1628, 2441)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 814/814 [00:04<00:00, 178.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "# 기존 데이터셋 경로 설정\n",
    "dataset_path = '../../dataset'\n",
    "\n",
    "name = '종욱'\n",
    "\n",
    "if not os.path.exists(dataset_path):\n",
    "    print(\"Reset the dataset path\")\n",
    "\n",
    "train_for_label_path = os.path.join(dataset_path, 'train_for_label')\n",
    "json_file_path = os.path.join(train_for_label_path, 'annotations/instances.json' )\n",
    "image_folder_path = os.path.join(train_for_label_path, 'images' )\n",
    "\n",
    "if not os.path.exists(train_for_label_path):\n",
    "    print('위에 셀들 재실행')\n",
    "\n",
    "num_files = len(os.listdir(image_folder_path))\n",
    "\n",
    "parts = 6\n",
    "images_per_part = num_files // parts\n",
    "remainder = num_files % parts\n",
    "\n",
    "divisions = []\n",
    "start = 0\n",
    "for i in range(parts):\n",
    "    end = start + images_per_part + (1 if i < remainder else 0) - 1\n",
    "    divisions.append((start, end))\n",
    "    start = end + 1\n",
    "\n",
    "name_lst = ['채아','민윤', '종욱', '찬종','명현','시현']\n",
    "\n",
    "if name in name_lst:\n",
    "    label_range = divisions[name_lst.index(name)]\n",
    "    print(\"레이블러:\", name, \"/ Label range:\", label_range)\n",
    "else:\n",
    "    print('입력 이름 오류, 이름 확인')\n",
    "\n",
    "target_folder_name = 'splited_'+str(label_range[0])+'_'+str(label_range[1])\n",
    "target_path = os.path.join(dataset_path, target_folder_name)\n",
    "fitlered_image_folder_path = os.path.join(target_path, 'images')\n",
    "fitlered_annotation_folder_path = os.path.join(target_path, 'annotations')\n",
    "\n",
    "if not os.path.exists(target_path) or not os.path.exists(fitlered_image_folder_path) or not os.path.exists(fitlered_annotation_folder_path):\n",
    "    os.makedirs(target_path)\n",
    "    os.makedirs(fitlered_image_folder_path)\n",
    "    os.makedirs(fitlered_annotation_folder_path)\n",
    "\n",
    "\n",
    "for i in tqdm(range(label_range[0], label_range[1] + 1)):\n",
    "        file_name = f\"{i:04d}.jpg\"  # Assuming file names are in the format '0000.jpg', '0001.jpg', etc.\n",
    "        source_file = os.path.join(image_folder_path, file_name)\n",
    "        target_file = os.path.join(fitlered_image_folder_path, file_name)\n",
    "\n",
    "        # Move file if it exists\n",
    "        if os.path.exists(source_file):\n",
    "            shutil.copy(source_file, target_file)\n",
    "            # print(f\"Moved {file_name}\")\n",
    "        else:\n",
    "            print(f\"{file_name} does not exist in the source path\")\n",
    "\n",
    "with open(json_file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "selected_image_ids = list(range(label_range[0], label_range[1] + 1))\n",
    "selected_filenames = [f\"{str(id).zfill(4)}.jpg\" for id in selected_image_ids]\n",
    "filtered_images = [image for image in data['images'] if image['file_name'] in selected_filenames]\n",
    "filtered_annotations = [annotation for annotation in data['annotations'] if annotation['image_id'] in selected_image_ids]\n",
    "\n",
    "data['images'] = filtered_images\n",
    "data['annotations'] = filtered_annotations\n",
    "\n",
    "filtered_json_file_name = 'instances.json'\n",
    "filtered_json_file_path = os.path.join(fitlered_annotation_folder_path, filtered_json_file_name)\n",
    "\n",
    "# 수정된 JSON 파일 저장\n",
    "with open(filtered_json_file_path, 'w') as file:\n",
    "    json.dump(data, file, indent=4)\n",
    "\n",
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "231219_mask",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
